{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/albertaillet/LELSD/blob/colab-setup/notebooks/train_lelsd_stylegan2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Clone repo and go into correct branch"
      ],
      "metadata": {
        "id": "4kq_s1FO81-G"
      },
      "id": "4kq_s1FO81-G"
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone --branch colab-setup https://github.com/albertaillet/LELSD/\n",
        "%cd LELSD"
      ],
      "metadata": {
        "id": "xy-v9jJHBfFT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b15630a-283c-4b93-ef0b-134c12355087"
      },
      "id": "xy-v9jJHBfFT",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'LELSD' already exists and is not an empty directory.\n",
            "/content/LELSD\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "id": "jLkrICI2BtY8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2c8a157-4d04-44c7-9e57-1fe85cf7bd07"
      },
      "id": "jLkrICI2BtY8",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 2)) (1.21.5)\n",
            "Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 3)) (8.0.4)\n",
            "Requirement already satisfied: pillow==8.3.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 4)) (8.3.1)\n",
            "Requirement already satisfied: scipy==1.7.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 5)) (1.7.1)\n",
            "Requirement already satisfied: torch==1.9.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 6)) (1.9.1)\n",
            "Requirement already satisfied: requests==2.26.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 8)) (2.26.0)\n",
            "Requirement already satisfied: tqdm==4.62.2 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 9)) (4.62.2)\n",
            "Requirement already satisfied: ninja==1.10.2 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 10)) (1.10.2)\n",
            "Requirement already satisfied: matplotlib==3.4.2 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 11)) (3.4.2)\n",
            "Requirement already satisfied: imageio==2.9.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 12)) (2.9.0)\n",
            "Requirement already satisfied: imgui==1.3.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 13)) (1.3.0)\n",
            "Requirement already satisfied: glfw==2.2.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 14)) (2.2.0)\n",
            "Requirement already satisfied: pyopengl==3.1.5 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 15)) (3.1.5)\n",
            "Requirement already satisfied: imageio-ffmpeg==0.4.3 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 16)) (0.4.3)\n",
            "Requirement already satisfied: pyspng in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 17)) (0.1.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 18)) (3.13)\n",
            "Requirement already satisfied: streamlit in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 21)) (1.8.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 22)) (3.2.5)\n",
            "Requirement already satisfied: lpips in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 24)) (0.1.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.9.1->-r requirements.txt (line 6)) (3.10.0.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests==2.26.0->-r requirements.txt (line 8)) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests==2.26.0->-r requirements.txt (line 8)) (1.24.3)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests==2.26.0->-r requirements.txt (line 8)) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests==2.26.0->-r requirements.txt (line 8)) (2021.10.8)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.4.2->-r requirements.txt (line 11)) (1.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.4.2->-r requirements.txt (line 11)) (3.0.7)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.4.2->-r requirements.txt (line 11)) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.4.2->-r requirements.txt (line 11)) (0.11.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from click>=8.0->-r requirements.txt (line 3)) (4.11.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7->matplotlib==3.4.2->-r requirements.txt (line 11)) (1.15.0)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.7/dist-packages (from streamlit->-r requirements.txt (line 21)) (0.10.2)\n",
            "Requirement already satisfied: altair>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from streamlit->-r requirements.txt (line 21)) (4.2.0)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.7/dist-packages (from streamlit->-r requirements.txt (line 21)) (21.4.0)\n",
            "Requirement already satisfied: watchdog in /usr/local/lib/python3.7/dist-packages (from streamlit->-r requirements.txt (line 21)) (2.1.7)\n",
            "Requirement already satisfied: pandas>=0.21.0 in /usr/local/lib/python3.7/dist-packages (from streamlit->-r requirements.txt (line 21)) (1.3.5)\n",
            "Requirement already satisfied: pydeck>=0.1.dev5 in /usr/local/lib/python3.7/dist-packages (from streamlit->-r requirements.txt (line 21)) (0.7.1)\n",
            "Requirement already satisfied: cachetools>=4.0 in /usr/local/lib/python3.7/dist-packages (from streamlit->-r requirements.txt (line 21)) (4.2.4)\n",
            "Requirement already satisfied: gitpython!=3.1.19 in /usr/local/lib/python3.7/dist-packages (from streamlit->-r requirements.txt (line 21)) (3.1.27)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from streamlit->-r requirements.txt (line 21)) (21.3)\n",
            "Requirement already satisfied: validators in /usr/local/lib/python3.7/dist-packages (from streamlit->-r requirements.txt (line 21)) (0.18.2)\n",
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.7/dist-packages (from streamlit->-r requirements.txt (line 21)) (6.0.1)\n",
            "Requirement already satisfied: tzlocal in /usr/local/lib/python3.7/dist-packages (from streamlit->-r requirements.txt (line 21)) (1.5.1)\n",
            "Requirement already satisfied: pympler>=0.9 in /usr/local/lib/python3.7/dist-packages (from streamlit->-r requirements.txt (line 21)) (1.0.1)\n",
            "Requirement already satisfied: protobuf!=3.11,>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from streamlit->-r requirements.txt (line 21)) (3.17.3)\n",
            "Requirement already satisfied: blinker in /usr/local/lib/python3.7/dist-packages (from streamlit->-r requirements.txt (line 21)) (1.4)\n",
            "Requirement already satisfied: tornado>=5.0 in /usr/local/lib/python3.7/dist-packages (from streamlit->-r requirements.txt (line 21)) (5.1.1)\n",
            "Requirement already satisfied: semver in /usr/local/lib/python3.7/dist-packages (from streamlit->-r requirements.txt (line 21)) (2.13.0)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.7/dist-packages (from altair>=3.2.0->streamlit->-r requirements.txt (line 21)) (0.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.7/dist-packages (from altair>=3.2.0->streamlit->-r requirements.txt (line 21)) (4.3.3)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.7/dist-packages (from altair>=3.2.0->streamlit->-r requirements.txt (line 21)) (0.11.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from altair>=3.2.0->streamlit->-r requirements.txt (line 21)) (2.11.3)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.7/dist-packages (from gitpython!=3.1.19->streamlit->-r requirements.txt (line 21)) (4.0.9)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.7/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19->streamlit->-r requirements.txt (line 21)) (5.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->click>=8.0->-r requirements.txt (line 3)) (3.7.0)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=3.0->altair>=3.2.0->streamlit->-r requirements.txt (line 21)) (5.4.0)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=3.0->altair>=3.2.0->streamlit->-r requirements.txt (line 21)) (0.18.1)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.21.0->streamlit->-r requirements.txt (line 21)) (2018.9)\n",
            "Requirement already satisfied: ipykernel>=5.1.2 in /usr/local/lib/python3.7/dist-packages (from pydeck>=0.1.dev5->streamlit->-r requirements.txt (line 21)) (6.10.0)\n",
            "Requirement already satisfied: traitlets>=4.3.2 in /usr/local/lib/python3.7/dist-packages (from pydeck>=0.1.dev5->streamlit->-r requirements.txt (line 21)) (5.1.1)\n",
            "Requirement already satisfied: ipywidgets>=7.0.0 in /usr/local/lib/python3.7/dist-packages (from pydeck>=0.1.dev5->streamlit->-r requirements.txt (line 21)) (7.7.0)\n",
            "Requirement already satisfied: debugpy<2.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit->-r requirements.txt (line 21)) (1.0.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit->-r requirements.txt (line 21)) (5.4.8)\n",
            "Requirement already satisfied: jupyter-client<8.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit->-r requirements.txt (line 21)) (5.3.5)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.7/dist-packages (from ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit->-r requirements.txt (line 21)) (1.5.4)\n",
            "Requirement already satisfied: ipython>=7.23.1 in /usr/local/lib/python3.7/dist-packages (from ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit->-r requirements.txt (line 21)) (7.32.0)\n",
            "Requirement already satisfied: matplotlib-inline<0.2.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit->-r requirements.txt (line 21)) (0.1.3)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit->-r requirements.txt (line 21)) (0.7.5)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit->-r requirements.txt (line 21)) (2.6.1)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.7/dist-packages (from ipython>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit->-r requirements.txt (line 21)) (4.8.0)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from ipython>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit->-r requirements.txt (line 21)) (3.0.28)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit->-r requirements.txt (line 21)) (57.4.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit->-r requirements.txt (line 21)) (4.4.2)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.7/dist-packages (from ipython>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit->-r requirements.txt (line 21)) (0.18.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.7/dist-packages (from ipython>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit->-r requirements.txt (line 21)) (0.2.0)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->-r requirements.txt (line 21)) (3.6.0)\n",
            "Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->-r requirements.txt (line 21)) (5.2.0)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->-r requirements.txt (line 21)) (0.2.0)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->-r requirements.txt (line 21)) (1.1.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit->-r requirements.txt (line 21)) (0.8.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->altair>=3.2.0->streamlit->-r requirements.txt (line 21)) (2.0.1)\n",
            "Requirement already satisfied: jupyter-core>=4.6.0 in /usr/local/lib/python3.7/dist-packages (from jupyter-client<8.0->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit->-r requirements.txt (line 21)) (4.9.2)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.7/dist-packages (from jupyter-client<8.0->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit->-r requirements.txt (line 21)) (22.3.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect>4.3->ipython>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit->-r requirements.txt (line 21)) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit->-r requirements.txt (line 21)) (0.2.5)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.7/dist-packages (from widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->-r requirements.txt (line 21)) (5.3.1)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->-r requirements.txt (line 21)) (0.13.3)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->-r requirements.txt (line 21)) (1.8.0)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->-r requirements.txt (line 21)) (5.6.1)\n",
            "Requirement already satisfied: torchvision>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from lpips->-r requirements.txt (line 24)) (0.10.1)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->-r requirements.txt (line 21)) (0.6.0)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->-r requirements.txt (line 21)) (0.8.4)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->-r requirements.txt (line 21)) (1.5.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->-r requirements.txt (line 21)) (0.7.1)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->-r requirements.txt (line 21)) (4.1.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->-r requirements.txt (line 21)) (0.5.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download the pretrained stylegan2 model from https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada-pytorch/pretrained/"
      ],
      "metadata": {
        "id": "cscSauz98lOf"
      },
      "id": "cscSauz98lOf"
    },
    {
      "cell_type": "code",
      "source": [
        "!ls pretrained/stylegan2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3EHYOLJIyUzj",
        "outputId": "54876118-c6c4-41f5-98c5-b39e251beb39"
      },
      "id": "3EHYOLJIyUzj",
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ffhq.pkl  readme.md\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada-pytorch/pretrained/ffhq.pkl -P pretrained/stylegan2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m9dkEZdNyJQG",
        "outputId": "4078178a-582c-414f-a1d8-ce507394b616"
      },
      "id": "m9dkEZdNyJQG",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-03-30 08:01:43--  https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada-pytorch/pretrained/ffhq.pkl\n",
            "Resolving nvlabs-fi-cdn.nvidia.com (nvlabs-fi-cdn.nvidia.com)... 108.159.227.118, 108.159.227.48, 108.159.227.98, ...\n",
            "Connecting to nvlabs-fi-cdn.nvidia.com (nvlabs-fi-cdn.nvidia.com)|108.159.227.118|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 381624121 (364M) [binary/octet-stream]\n",
            "Saving to: ‘pretrained/stylegan2/ffhq.pkl’\n",
            "\n",
            "ffhq.pkl            100%[===================>] 363.94M  41.7MB/s    in 11s     \n",
            "\n",
            "2022-03-30 08:01:55 (33.0 MB/s) - ‘pretrained/stylegan2/ffhq.pkl’ saved [381624121/381624121]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download the pretrained segmentation model from https://github.com/zllrunning/face-parsing.PyTorch"
      ],
      "metadata": {
        "id": "FjvZE_6r8KUl"
      },
      "id": "FjvZE_6r8KUl"
    },
    {
      "cell_type": "code",
      "source": [
        "!ls pretrained/face_bisenet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kH0Awof82xOp",
        "outputId": "6be7c6ea-aeba-4787-f9cb-5cf762ec0c81"
      },
      "id": "kH0Awof82xOp",
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model.pth  readme.md\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown --id 154JgKpzCPW82qINcVieuPH3fZ2e0P812 -O pretrained/face_bisenet/model.pth"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H776Lwm-22Im",
        "outputId": "7e806232-eada-45c8-be1f-f6f4f1e01463"
      },
      "id": "H776Lwm-22Im",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=154JgKpzCPW82qINcVieuPH3fZ2e0P812\n",
            "To: /content/LELSD/pretrained/face_bisenet/model.pth\n",
            "100% 53.3M/53.3M [00:00<00:00, 247MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "8f050d55-2b6d-40cc-b81b-3c550279086d",
      "metadata": {
        "id": "8f050d55-2b6d-40cc-b81b-3c550279086d",
        "outputId": "e5e021b4-69bb-48b4-a1e1-b1a934158a2d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ]
        }
      ],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import sys\n",
        "import torch\n",
        "\n",
        "import models\n",
        "from utils.stylegan2_utils import StyleGAN2SampleGenerator\n",
        "from utils.segmentation_utils import FaceSegmentation, StuffSegmentation, GANLinearSegmentation\n",
        "from lelsd import LELSD"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "760c75e9-8cdf-4274-837e-981469fc03b3",
      "metadata": {
        "id": "760c75e9-8cdf-4274-837e-981469fc03b3"
      },
      "source": [
        "# Training StyleGAN2 with Supervised Segmentation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "233ed233-48da-4bd4-9003-fc18de04db40",
      "metadata": {
        "tags": [],
        "id": "233ed233-48da-4bd4-9003-fc18de04db40"
      },
      "source": [
        "### StyleGAN2 FFHQ"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda')\n",
        "\n",
        "exp_dir = \"out\"\n",
        "G2 = models.get_model(\"stylegan2\", \"pretrained/stylegan2/ffhq.pkl\")\n",
        "stylegan2_sample_generator = StyleGAN2SampleGenerator(G=G2, device=device)\n",
        "\n",
        "face_bisenet = models.get_model(\"face_bisenet\", \"pretrained/face_bisenet/model.pth\")\n",
        "face_segmentation = FaceSegmentation(face_bisenet=face_bisenet, device=device)\n",
        "\n",
        "latent_space = \"Z\"\n",
        "loss_function = \"L2\"\n",
        "mask_aggregation = 'average'\n",
        "num_latent_dirs = 1\n",
        "part_name = \"mouth\"\n",
        "face_parts = [\"mouth\", \"u_lip\", \"l_lip\"]\n",
        "lr = 0.001\n",
        "min_alpha_value = -1.0\n",
        "max_alpha_value = 1.0\n",
        "min_abs_alpha_value = 0.0\n",
        "gamma_correlation = 5.0\n",
        "onehot_temperature = 0.001\n",
        "batch_size = 1\n",
        "localization_layers = list(range(1, 18))\n",
        "localization_layer_weights = None\n",
        "log_dir = f'{exp_dir}/lelsd_stylegan2_ffhq/{latent_space}_{loss_function}_{mask_aggregation}/{num_latent_dirs}D/face_bisenet/{part_name}'\n",
        "lelsd = LELSD(device=device,\n",
        "              localization_layers=localization_layers,\n",
        "              semantic_parts=face_parts,\n",
        "              loss_function=loss_function,\n",
        "              localization_layer_weights=localization_layer_weights,\n",
        "              mode='foreground',\n",
        "              mask_aggregation=mask_aggregation,\n",
        "              n_layers=18,\n",
        "              latent_dim=512,\n",
        "              num_latent_dirs=num_latent_dirs,\n",
        "              learning_rate=lr,\n",
        "              batch_size=batch_size,\n",
        "              gamma_correlation=gamma_correlation,\n",
        "              unit_norm=False,\n",
        "              latent_space=latent_space,\n",
        "              onehot_temperature=onehot_temperature,\n",
        "              min_alpha_value=min_alpha_value,\n",
        "              max_alpha_value=max_alpha_value,\n",
        "              min_abs_alpha_value=min_abs_alpha_value,\n",
        "              log_dir=log_dir,\n",
        "              )\n",
        "lelsd.fit(stylegan2_sample_generator, face_segmentation, num_batches=200 * num_latent_dirs,\n",
        "          num_lr_halvings=3,\n",
        "          pgbar=True, summary=True)\n",
        "lelsd.save()"
      ],
      "metadata": {
        "id": "iNqfpd6T8-4-",
        "outputId": "f0098db0-d2d8-4801-f272-efc7bbe9a0fd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "iNqfpd6T8-4-",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 16%|█▌        | 32/200 [00:28<02:26,  1.15it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0fedc90d-56a9-4f36-9c90-9150e5ccc1b8",
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "tags": [],
        "id": "0fedc90d-56a9-4f36-9c90-9150e5ccc1b8"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda')\n",
        "\n",
        "exp_dir = \"out\"\n",
        "G2 = models.get_model(\"stylegan2\", \"pretrained/stylegan2/ffhq.pkl\")\n",
        "stylegan2_sample_generator = StyleGAN2SampleGenerator(G=G2, device=device)\n",
        "\n",
        "face_bisenet = models.get_model(\"face_bisenet\", \"pretrained/face_bisenet/model.pth\")\n",
        "face_segmentation = FaceSegmentation(face_bisenet=face_bisenet, device=device)\n",
        "\n",
        "for latent_space in [\"Z\", \"W\", \"W+\"]:\n",
        "    for loss_function in [\"L2\"]:\n",
        "        for mask_aggregation in [\n",
        "            'average',\n",
        "            'union',\n",
        "            'intersection',\n",
        "        ]:\n",
        "\n",
        "            for num_latent_dirs in [1, 2]:\n",
        "                for part_name, face_parts in zip(\n",
        "                        [\n",
        "                            \"mouth\",\n",
        "                            \"skin\",\n",
        "                            \"eyes\",\n",
        "                            \"nose\",\n",
        "                            \"ears\",\n",
        "                            \"background\",\n",
        "                            \"eyebrows\",\n",
        "                            \"hair\",\n",
        "                            \"cloth\", \"eyeglass\"\n",
        "\n",
        "                        ],\n",
        "                        [\n",
        "                            [\"mouth\", \"u_lip\", \"l_lip\"],\n",
        "                            [\"skin\"],\n",
        "                            [\"l_eye\", \"r_eye\"],\n",
        "                            [\"nose\"],\n",
        "                            [\"l_ear\", \"r_ear\", \"earrings\"],\n",
        "                            [\"background\"],\n",
        "                            [\"l_brow\", \"r_brow\"],\n",
        "                            [\"hair\", \"hat\"],\n",
        "                            [\"hair\"],\n",
        "                            [\"cloth\", \"neck\", \"necklace\"],\n",
        "                            [\"eyeglass\"]\n",
        "\n",
        "                        ]\n",
        "                ):\n",
        "                    lr = 0.001\n",
        "                    min_alpha_value = -1.0\n",
        "                    max_alpha_value = 1.0\n",
        "                    min_abs_alpha_value = 0.0\n",
        "                    gamma_correlation = 5.0\n",
        "                    onehot_temperature = 0.001\n",
        "                    batch_size = 4\n",
        "                    localization_layers = list(range(1, 18))\n",
        "                    localization_layer_weights = None\n",
        "                    log_dir = f'{exp_dir}/lelsd_stylegan2_ffhq/{latent_space}_{loss_function}_{mask_aggregation}/{num_latent_dirs}D/face_bisenet/{part_name}'\n",
        "                    lelsd = LELSD(device=device,\n",
        "                                  localization_layers=localization_layers,\n",
        "                                  semantic_parts=face_parts,\n",
        "                                  loss_function=loss_function,\n",
        "                                  localization_layer_weights=localization_layer_weights,\n",
        "                                  mode='foreground',\n",
        "                                  mask_aggregation=mask_aggregation,\n",
        "                                  n_layers=18,\n",
        "                                  latent_dim=512,\n",
        "                                  num_latent_dirs=num_latent_dirs,\n",
        "                                  learning_rate=lr,\n",
        "                                  batch_size=batch_size,\n",
        "                                  gamma_correlation=gamma_correlation,\n",
        "                                  unit_norm=False,\n",
        "                                  latent_space=latent_space,\n",
        "                                  onehot_temperature=onehot_temperature,\n",
        "                                  min_alpha_value=min_alpha_value,\n",
        "                                  max_alpha_value=max_alpha_value,\n",
        "                                  min_abs_alpha_value=min_abs_alpha_value,\n",
        "                                  log_dir=log_dir,\n",
        "                                  )\n",
        "\n",
        "                    lelsd.fit(stylegan2_sample_generator, face_segmentation, num_batches=200 * num_latent_dirs,\n",
        "                              num_lr_halvings=3,\n",
        "                              pgbar=True, summary=True)\n",
        "                    lelsd.save()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "db10007d-6252-453e-8814-0261ed1031be",
      "metadata": {
        "tags": [],
        "id": "db10007d-6252-453e-8814-0261ed1031be"
      },
      "source": [
        "### StyleGAN2 LSUN Church"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1c1f1700-a03d-43ae-a631-467ce19ce1ed",
      "metadata": {
        "id": "1c1f1700-a03d-43ae-a631-467ce19ce1ed",
        "outputId": "33810ea7-5956-417a-c7a5-fdfc119f8072"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 200/200 [03:08<00:00,  1.06it/s]\n",
            "100%|██████████| 200/200 [03:09<00:00,  1.06it/s]\n",
            "100%|██████████| 200/200 [03:09<00:00,  1.06it/s]\n",
            "100%|██████████| 200/200 [03:09<00:00,  1.06it/s]\n",
            "100%|██████████| 400/400 [06:18<00:00,  1.06it/s]\n",
            "100%|██████████| 400/400 [06:19<00:00,  1.05it/s]\n",
            "100%|██████████| 400/400 [06:19<00:00,  1.05it/s]\n",
            "100%|██████████| 400/400 [06:19<00:00,  1.06it/s]\n",
            "100%|██████████| 200/200 [03:09<00:00,  1.05it/s]\n",
            "100%|██████████| 200/200 [03:09<00:00,  1.05it/s]\n",
            "100%|██████████| 200/200 [03:09<00:00,  1.05it/s]\n",
            "100%|██████████| 200/200 [03:10<00:00,  1.05it/s]\n",
            " 13%|█▎        | 51/400 [00:51<05:30,  1.06it/s]"
          ]
        }
      ],
      "source": [
        "device = torch.device('cuda')\n",
        "\n",
        "exp_dir = \"../out\"\n",
        "G2 = models.get_model(\"stylegan2\", \"../pretrained/stylegan2/stylegan2-church-config-f.pkl\")\n",
        "stylegan2_sample_generator = StyleGAN2SampleGenerator(G=G2, device=device)\n",
        "\n",
        "deeplabv2_resnet101 = models.get_model(\"cocostuff_deeplab\",\n",
        "                                       \"../pretrained/cocostuff_deeplab/deeplabv2_resnet101_msc-cocostuff164k-100000.pth\")\n",
        "segmentation_model = StuffSegmentation(deeplabv2_resnet101=deeplabv2_resnet101, \n",
        "                                       config_path=\"../pretrained/cocostuff_deeplab/\", device=device)\n",
        "\n",
        "for latent_space in [\"Z\", \"W\", \"W+\"]:\n",
        "    for loss_function in [\"L2\"]:\n",
        "        for mask_aggregation in [\n",
        "            'average',\n",
        "            'union',\n",
        "            'intersection',\n",
        "        ]:\n",
        "\n",
        "            for num_latent_dirs in [1, 2]:\n",
        "                for part_name, sub_parts in zip(\n",
        "                        [\n",
        "                            \"church\",\n",
        "                            \"sky\", \"vegetation\", \"ground\"\n",
        "\n",
        "                        ],\n",
        "                        [\n",
        "                            [\"building-other\", \"house\"],\n",
        "                            [\"sky-other\", \"clouds\"],\n",
        "                            [\"tree\", \"grass\", \"bush\", \"plant-other\"],\n",
        "                            [\"dirt\", \"mud\", \"sand\", \"gravel\", \"ground-other\", \"road\", \"pavement\"],\n",
        "\n",
        "                        ]\n",
        "                ):\n",
        "                    lr = 0.001\n",
        "                    min_alpha_value = -1.0\n",
        "                    max_alpha_value = 1.0\n",
        "                    min_abs_alpha_value = 0.0\n",
        "                    gamma_correlation = 5.0\n",
        "                    onehot_temperature = 0.001\n",
        "                    batch_size = 4\n",
        "                    localization_layers = list(range(1, 14))\n",
        "                    localization_layer_weights = None\n",
        "                    log_dir = f'{exp_dir}/lelsd_stylegan2_lsun_church/{latent_space}_{loss_function}_{mask_aggregation}/{num_latent_dirs}D/deeplab/{part_name}'\n",
        "                    lelsd = LELSD(device=device,\n",
        "                                  localization_layers=localization_layers,\n",
        "                                  semantic_parts=sub_parts,\n",
        "                                  loss_function=loss_function,\n",
        "                                  localization_layer_weights=localization_layer_weights,\n",
        "                                  mode='foreground',\n",
        "                                  mask_aggregation=mask_aggregation,\n",
        "                                  n_layers=14,\n",
        "                                  latent_dim=512,\n",
        "                                  num_latent_dirs=num_latent_dirs,\n",
        "                                  learning_rate=lr,\n",
        "                                  batch_size=batch_size,\n",
        "                                  gamma_correlation=gamma_correlation,\n",
        "                                  unit_norm=False,\n",
        "                                  latent_space=latent_space,\n",
        "                                  onehot_temperature=onehot_temperature,\n",
        "                                  min_alpha_value=min_alpha_value,\n",
        "                                  max_alpha_value=max_alpha_value,\n",
        "                                  min_abs_alpha_value=min_abs_alpha_value,\n",
        "                                  log_dir=log_dir,\n",
        "                                  )\n",
        "\n",
        "                    lelsd.fit(stylegan2_sample_generator, segmentation_model, num_batches=200 * num_latent_dirs,\n",
        "                              num_lr_halvings=3,\n",
        "                              pgbar=True, summary=True)\n",
        "                    lelsd.save()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dc4514f1-a9e4-4db5-98f3-4646dfe823f2",
      "metadata": {
        "id": "dc4514f1-a9e4-4db5-98f3-4646dfe823f2"
      },
      "source": [
        "### StyleGAN2 LSUN Car"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7fb2be38-35ff-4f38-a7cf-97628c5fd937",
      "metadata": {
        "id": "7fb2be38-35ff-4f38-a7cf-97628c5fd937",
        "outputId": "835936fa-10bc-4db6-e183-b6a558198820"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 200/200 [03:29<00:00,  1.05s/it]\n",
            "100%|██████████| 200/200 [03:30<00:00,  1.05s/it]\n",
            "100%|██████████| 200/200 [03:30<00:00,  1.05s/it]\n",
            "100%|██████████| 200/200 [03:30<00:00,  1.05s/it]\n",
            "100%|██████████| 400/400 [07:01<00:00,  1.05s/it]\n",
            "100%|██████████| 400/400 [07:03<00:00,  1.06s/it]\n",
            "100%|██████████| 400/400 [07:01<00:00,  1.05s/it]\n",
            "100%|██████████| 400/400 [07:12<00:00,  1.08s/it]\n",
            "100%|██████████| 200/200 [03:33<00:00,  1.07s/it]\n",
            "100%|██████████| 200/200 [03:35<00:00,  1.08s/it]\n",
            "100%|██████████| 200/200 [03:33<00:00,  1.07s/it]\n",
            "100%|██████████| 200/200 [03:31<00:00,  1.06s/it]\n",
            "100%|██████████| 400/400 [07:02<00:00,  1.06s/it]\n",
            "100%|██████████| 400/400 [07:03<00:00,  1.06s/it]\n",
            "100%|██████████| 400/400 [07:08<00:00,  1.07s/it]\n",
            "100%|██████████| 400/400 [07:02<00:00,  1.06s/it]\n"
          ]
        }
      ],
      "source": [
        "device = torch.device('cuda')\n",
        "\n",
        "exp_dir = \"../out\"\n",
        "G2 = models.get_model(\"stylegan2\", \"../pretrained/stylegan2/stylegan2-car-config-f.pkl\")\n",
        "stylegan2_sample_generator = StyleGAN2SampleGenerator(G=G2, device=device)\n",
        "\n",
        "deeplabv2_resnet101 = models.get_model(\"cocostuff_deeplab\",\n",
        "                                       \"../pretrained/cocostuff_deeplab/deeplabv2_resnet101_msc-cocostuff164k-100000.pth\")\n",
        "segmentation_model = StuffSegmentation(deeplabv2_resnet101=deeplabv2_resnet101,\n",
        "                                       config_path=\"../pretrained/cocostuff_deeplab/\", device=device)\n",
        "\n",
        "for latent_space in [\"W\", \"W+\"]:\n",
        "    for loss_function in [\"L2\"]:\n",
        "        for mask_aggregation in [\n",
        "            'average',\n",
        "        ]:\n",
        "            for num_latent_dirs in [1, 2]:\n",
        "                for part_name, sub_parts in zip(\n",
        "                        [\n",
        "                            \"car\",\n",
        "                            \"road\", \"sky\", \"grass+tree\",\n",
        "\n",
        "                        ],\n",
        "                        [\n",
        "                            [\"car\", \"truck\", \"bus\", \"motorcycle\"],\n",
        "                            [\"road\", \"pavement\", \"dirt\"],\n",
        "                            [\"sky-other\", \"clouds\"],\n",
        "                            [\"tree\", \"grass\", \"bush\", \"plant-other\"],\n",
        "                        ]\n",
        "                ):\n",
        "                    lr = 0.001\n",
        "                    min_alpha_value = -1.0\n",
        "                    max_alpha_value = 1.0\n",
        "                    min_abs_alpha_value = 0.0\n",
        "                    gamma_correlation = 5.0\n",
        "                    onehot_temperature = 0.001\n",
        "                    batch_size = 4\n",
        "                    localization_layers = list(range(1, 16))\n",
        "                    localization_layer_weights = None\n",
        "                    log_dir = f'{exp_dir}/lelsd_stylegan2_lsun_car/{latent_space}_{loss_function}_{mask_aggregation}/{num_latent_dirs}D/deeplab/{part_name}'\n",
        "                    lelsd = LELSD(device=device,\n",
        "                                  localization_layers=localization_layers,\n",
        "                                  semantic_parts=sub_parts,\n",
        "                                  loss_function=loss_function,\n",
        "                                  localization_layer_weights=localization_layer_weights,\n",
        "                                  mode='foreground',\n",
        "                                  mask_aggregation=mask_aggregation,\n",
        "                                  n_layers=16,\n",
        "                                  latent_dim=512,\n",
        "                                  num_latent_dirs=num_latent_dirs,\n",
        "                                  learning_rate=lr,\n",
        "                                  batch_size=batch_size,\n",
        "                                  gamma_correlation=gamma_correlation,\n",
        "                                  unit_norm=False,\n",
        "                                  latent_space=latent_space,\n",
        "                                  onehot_temperature=onehot_temperature,\n",
        "                                  min_alpha_value=min_alpha_value,\n",
        "                                  max_alpha_value=max_alpha_value,\n",
        "                                  min_abs_alpha_value=min_abs_alpha_value,\n",
        "                                  log_dir=log_dir,\n",
        "                                  )\n",
        "\n",
        "                    lelsd.fit(stylegan2_sample_generator, segmentation_model, num_batches=200 * num_latent_dirs,\n",
        "                              num_lr_halvings=3,\n",
        "                              pgbar=True, summary=True)\n",
        "                    lelsd.save()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9f89ace7-be9b-4c34-890f-1d07f829c136",
      "metadata": {
        "id": "9f89ace7-be9b-4c34-890f-1d07f829c136"
      },
      "source": [
        "### StyleGAN2 LSUN Horse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1a2d5101-9f30-4b9a-b5da-83a329eab036",
      "metadata": {
        "id": "1a2d5101-9f30-4b9a-b5da-83a329eab036",
        "outputId": "4393aa5f-0e3c-49d4-b7c5-be7b50a8aeb5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 200/200 [03:08<00:00,  1.06it/s]\n",
            "100%|██████████| 200/200 [03:08<00:00,  1.06it/s]\n",
            "100%|██████████| 200/200 [03:08<00:00,  1.06it/s]\n",
            "100%|██████████| 200/200 [03:09<00:00,  1.06it/s]\n",
            "100%|██████████| 200/200 [03:09<00:00,  1.06it/s]\n",
            "100%|██████████| 400/400 [06:18<00:00,  1.06it/s]\n",
            "100%|██████████| 400/400 [06:18<00:00,  1.06it/s]\n",
            "100%|██████████| 400/400 [06:17<00:00,  1.06it/s]\n",
            "100%|██████████| 400/400 [06:18<00:00,  1.06it/s]\n",
            "100%|██████████| 400/400 [06:17<00:00,  1.06it/s]\n",
            " 40%|████      | 80/200 [01:15<01:53,  1.06it/s]"
          ]
        }
      ],
      "source": [
        "device = torch.device('cuda')\n",
        "\n",
        "exp_dir = \"../out\"\n",
        "G2 = models.get_model(\"stylegan2\", \"../pretrained/stylegan2/stylegan2-horse-config-f.pkl\")\n",
        "stylegan2_sample_generator = StyleGAN2SampleGenerator(G=G2, device=device)\n",
        "\n",
        "deeplabv2_resnet101 = models.get_model(\"cocostuff_deeplab\",\n",
        "                                       \"../pretrained/cocostuff_deeplab/deeplabv2_resnet101_msc-cocostuff164k-100000.pth\")\n",
        "segmentation_model = StuffSegmentation(deeplabv2_resnet101=deeplabv2_resnet101,\n",
        "                                       config_path=\"../pretrained/cocostuff_deeplab/\", device=device)\n",
        "\n",
        "for latent_space in [\"W\", \"W+\"]:\n",
        "    for loss_function in [\"L2\"]:\n",
        "        for mask_aggregation in [\n",
        "            'average',\n",
        "        ]:\n",
        "            for num_latent_dirs in [1, 2]:\n",
        "                for part_name, sub_parts in zip(\n",
        "                        [\n",
        "                            \"horse\",\n",
        "                            \"person\", \"sky\", \"grass+tree\", \"ground\"\n",
        "\n",
        "                        ],\n",
        "                        [\n",
        "                            [\"horse\"],\n",
        "                            [\"person\"],\n",
        "                            [\"sky-other\", \"clouds\"],\n",
        "                            [\"tree\", \"grass\", \"bush\", \"plant-other\"],\n",
        "                            [\"dirt\", \"mud\", \"sand\", \"gravel\", \"ground-other\", \"road\", \"pavement\"],\n",
        "\n",
        "                        ]\n",
        "                ):\n",
        "                    lr = 0.001\n",
        "                    min_alpha_value = -1.0\n",
        "                    max_alpha_value = 1.0\n",
        "                    min_abs_alpha_value = 0.0\n",
        "                    gamma_correlation = 5.0\n",
        "                    onehot_temperature = 0.001\n",
        "                    batch_size = 4\n",
        "                    localization_layers = list(range(1, 14))\n",
        "                    localization_layer_weights = None\n",
        "                    log_dir = f'{exp_dir}/lelsd_stylegan2_lsun_horse/{latent_space}_{loss_function}_{mask_aggregation}/{num_latent_dirs}D/deeplab/{part_name}'\n",
        "                    lelsd = LELSD(device=device,\n",
        "                                  localization_layers=localization_layers,\n",
        "                                  semantic_parts=sub_parts,\n",
        "                                  loss_function=loss_function,\n",
        "                                  localization_layer_weights=localization_layer_weights,\n",
        "                                  mode='foreground',\n",
        "                                  mask_aggregation=mask_aggregation,\n",
        "                                  n_layers=14,\n",
        "                                  latent_dim=512,\n",
        "                                  num_latent_dirs=num_latent_dirs,\n",
        "                                  learning_rate=lr,\n",
        "                                  batch_size=batch_size,\n",
        "                                  gamma_correlation=gamma_correlation,\n",
        "                                  unit_norm=False,\n",
        "                                  latent_space=latent_space,\n",
        "                                  onehot_temperature=onehot_temperature,\n",
        "                                  min_alpha_value=min_alpha_value,\n",
        "                                  max_alpha_value=max_alpha_value,\n",
        "                                  min_abs_alpha_value=min_abs_alpha_value,\n",
        "                                  log_dir=log_dir,\n",
        "                                  )\n",
        "\n",
        "                    lelsd.fit(stylegan2_sample_generator, segmentation_model, num_batches=200 * num_latent_dirs,\n",
        "                              num_lr_halvings=3,\n",
        "                              pgbar=True, summary=True)\n",
        "                    lelsd.save()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c161aa35-adff-41ce-8855-2c76a212b5c9",
      "metadata": {
        "id": "c161aa35-adff-41ce-8855-2c76a212b5c9"
      },
      "source": [
        "### StyleGAN2 MetFaces"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c7d4206-cb07-483e-9b0d-80d0bdd6a93a",
      "metadata": {
        "id": "3c7d4206-cb07-483e-9b0d-80d0bdd6a93a"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda')\n",
        "\n",
        "exp_dir = \"../out\"\n",
        "G2 = models.get_model(\"stylegan2\", \"../pretrained/stylegan2/metfaces.pkl\")\n",
        "stylegan2_sample_generator = StyleGAN2SampleGenerator(G=G2, device=device)\n",
        "\n",
        "face_bisenet = models.get_model(\"face_bisenet\", \"../pretrained/face_bisenet/model.pth\")\n",
        "face_segmentation = FaceSegmentation(face_bisenet=face_bisenet, device=device)\n",
        "\n",
        "for latent_space in [\"W\", \"W+\"]:\n",
        "    for loss_function in [\"L2\"]:\n",
        "        for mask_aggregation in [\n",
        "            'average',\n",
        "        ]:\n",
        "\n",
        "            for num_latent_dirs in [1, 2]:\n",
        "                for part_name, face_parts in zip(\n",
        "                        [\n",
        "                            \"mouth\",\n",
        "                            \"skin\",\n",
        "                            \"eyes\",\n",
        "                            \"nose\",\n",
        "                            \"ears\",\n",
        "                            \"background\",\n",
        "                            \"eyebrows\",\n",
        "                            \"hair\",\n",
        "                            \"cloth\",\n",
        "                        ],\n",
        "                        [\n",
        "                            [\"mouth\", \"u_lip\", \"l_lip\"],\n",
        "                            [\"skin\"],\n",
        "                            [\"l_eye\", \"r_eye\"],\n",
        "                            [\"nose\"],\n",
        "                            [\"l_ear\", \"r_ear\", \"earrings\"],\n",
        "                            [\"background\"],\n",
        "                            [\"l_brow\", \"r_brow\"],\n",
        "                            [\"hair\", \"hat\"],\n",
        "                            [\"hair\"],\n",
        "                            [\"cloth\", \"neck\", \"necklace\"],\n",
        "\n",
        "                        ]\n",
        "                ):\n",
        "                    lr = 0.001\n",
        "                    min_alpha_value = -1.0\n",
        "                    max_alpha_value = 1.0\n",
        "                    min_abs_alpha_value = 0.0\n",
        "                    gamma_correlation = 5.0\n",
        "                    onehot_temperature = 0.001\n",
        "                    batch_size = 4\n",
        "                    localization_layers = list(range(1, 18))\n",
        "                    localization_layer_weights = None\n",
        "                    log_dir = f'{exp_dir}/lelsd_stylegan2_metfaces/{latent_space}_{loss_function}_{mask_aggregation}/{num_latent_dirs}D/face_bisenet/{part_name}'\n",
        "                    lelsd = LELSD(device=device,\n",
        "                                  localization_layers=localization_layers,\n",
        "                                  semantic_parts=face_parts,\n",
        "                                  loss_function=loss_function,\n",
        "                                  localization_layer_weights=localization_layer_weights,\n",
        "                                  mode='foreground',\n",
        "                                  mask_aggregation=mask_aggregation,\n",
        "                                  n_layers=18,\n",
        "                                  latent_dim=512,\n",
        "                                  num_latent_dirs=num_latent_dirs,\n",
        "                                  learning_rate=lr,\n",
        "                                  batch_size=batch_size,\n",
        "                                  gamma_correlation=gamma_correlation,\n",
        "                                  unit_norm=False,\n",
        "                                  latent_space=latent_space,\n",
        "                                  onehot_temperature=onehot_temperature,\n",
        "                                  min_alpha_value=min_alpha_value,\n",
        "                                  max_alpha_value=max_alpha_value,\n",
        "                                  min_abs_alpha_value=min_abs_alpha_value,\n",
        "                                  log_dir=log_dir,\n",
        "                                  )\n",
        "\n",
        "                    lelsd.fit(stylegan2_sample_generator, face_segmentation, num_batches=200 * num_latent_dirs,\n",
        "                              num_lr_halvings=3,\n",
        "                              pgbar=True, summary=True)\n",
        "                    lelsd.save()\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    },
    "colab": {
      "name": "train_lelsd_stylegan2.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}