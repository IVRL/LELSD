{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/albertaillet/LELSD/blob/colab-setup/notebooks/train_lelsd_stylegan2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Clone repo and go into correct branch\n",
        "!git clone --branch colab-setup https://github.com/albertaillet/LELSD/\n",
        "%cd LELSD"
      ],
      "metadata": {
        "id": "xy-v9jJHBfFT",
        "outputId": "b6cbda82-c2db-49f1-b53f-fe731e84d945",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "xy-v9jJHBfFT",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'LELSD' already exists and is not an empty directory.\n",
            "/content/LELSD\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "id": "jLkrICI2BtY8"
      },
      "id": "jLkrICI2BtY8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8f050d55-2b6d-40cc-b81b-3c550279086d",
      "metadata": {
        "id": "8f050d55-2b6d-40cc-b81b-3c550279086d"
      },
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "!export FORCE_CUDA=\"1\"\n",
        "\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import sys\n",
        "import torch\n",
        "\n",
        "import models\n",
        "from utils.stylegan2_utils import StyleGAN2SampleGenerator\n",
        "from utils.segmentation_utils import FaceSegmentation, StuffSegmentation, GANLinearSegmentation\n",
        "from lelsd import LELSD"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "760c75e9-8cdf-4274-837e-981469fc03b3",
      "metadata": {
        "id": "760c75e9-8cdf-4274-837e-981469fc03b3"
      },
      "source": [
        "# Training StyleGAN2 with Supervised Segmentation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "233ed233-48da-4bd4-9003-fc18de04db40",
      "metadata": {
        "tags": [],
        "id": "233ed233-48da-4bd4-9003-fc18de04db40"
      },
      "source": [
        "### StyleGAN2 FFHQ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0fedc90d-56a9-4f36-9c90-9150e5ccc1b8",
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "tags": [],
        "id": "0fedc90d-56a9-4f36-9c90-9150e5ccc1b8"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda')\n",
        "\n",
        "exp_dir = \"../out\"\n",
        "G2 = models.get_model(\"stylegan2\", \"../pretrained/stylegan2/ffhq.pkl\")\n",
        "stylegan2_sample_generator = StyleGAN2SampleGenerator(G=G2, device=device)\n",
        "\n",
        "face_bisenet = models.get_model(\"face_bisenet\", \"../pretrained/face_bisenet/model.pth\")\n",
        "face_segmentation = FaceSegmentation(face_bisenet=face_bisenet, device=device)\n",
        "\n",
        "for latent_space in [\"Z\", \"W\", \"W+\"]:\n",
        "    for loss_function in [\"L2\"]:\n",
        "        for mask_aggregation in [\n",
        "            'average',\n",
        "            'union',\n",
        "            'intersection',\n",
        "        ]:\n",
        "\n",
        "            for num_latent_dirs in [1, 2]:\n",
        "                for part_name, face_parts in zip(\n",
        "                        [\n",
        "                            \"mouth\",\n",
        "                            \"skin\",\n",
        "                            \"eyes\",\n",
        "                            \"nose\",\n",
        "                            \"ears\",\n",
        "                            \"background\",\n",
        "                            \"eyebrows\",\n",
        "                            \"hair\",\n",
        "                            \"cloth\", \"eyeglass\"\n",
        "\n",
        "                        ],\n",
        "                        [\n",
        "                            [\"mouth\", \"u_lip\", \"l_lip\"],\n",
        "                            [\"skin\"],\n",
        "                            [\"l_eye\", \"r_eye\"],\n",
        "                            [\"nose\"],\n",
        "                            [\"l_ear\", \"r_ear\", \"earrings\"],\n",
        "                            [\"background\"],\n",
        "                            [\"l_brow\", \"r_brow\"],\n",
        "                            [\"hair\", \"hat\"],\n",
        "                            [\"hair\"],\n",
        "                            [\"cloth\", \"neck\", \"necklace\"],\n",
        "                            [\"eyeglass\"]\n",
        "\n",
        "                        ]\n",
        "                ):\n",
        "                    lr = 0.001\n",
        "                    min_alpha_value = -1.0\n",
        "                    max_alpha_value = 1.0\n",
        "                    min_abs_alpha_value = 0.0\n",
        "                    gamma_correlation = 5.0\n",
        "                    onehot_temperature = 0.001\n",
        "                    batch_size = 4\n",
        "                    localization_layers = list(range(1, 18))\n",
        "                    localization_layer_weights = None\n",
        "                    log_dir = f'{exp_dir}/lelsd_stylegan2_ffhq/{latent_space}_{loss_function}_{mask_aggregation}/{num_latent_dirs}D/face_bisenet/{part_name}'\n",
        "                    lelsd = LELSD(device=device,\n",
        "                                  localization_layers=localization_layers,\n",
        "                                  semantic_parts=face_parts,\n",
        "                                  loss_function=loss_function,\n",
        "                                  localization_layer_weights=localization_layer_weights,\n",
        "                                  mode='foreground',\n",
        "                                  mask_aggregation=mask_aggregation,\n",
        "                                  n_layers=18,\n",
        "                                  latent_dim=512,\n",
        "                                  num_latent_dirs=num_latent_dirs,\n",
        "                                  learning_rate=lr,\n",
        "                                  batch_size=batch_size,\n",
        "                                  gamma_correlation=gamma_correlation,\n",
        "                                  unit_norm=False,\n",
        "                                  latent_space=latent_space,\n",
        "                                  onehot_temperature=onehot_temperature,\n",
        "                                  min_alpha_value=min_alpha_value,\n",
        "                                  max_alpha_value=max_alpha_value,\n",
        "                                  min_abs_alpha_value=min_abs_alpha_value,\n",
        "                                  log_dir=log_dir,\n",
        "                                  )\n",
        "\n",
        "                    lelsd.fit(stylegan2_sample_generator, face_segmentation, num_batches=200 * num_latent_dirs,\n",
        "                              num_lr_halvings=3,\n",
        "                              pgbar=True, summary=True)\n",
        "                    lelsd.save()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "db10007d-6252-453e-8814-0261ed1031be",
      "metadata": {
        "tags": [],
        "id": "db10007d-6252-453e-8814-0261ed1031be"
      },
      "source": [
        "### StyleGAN2 LSUN Church"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1c1f1700-a03d-43ae-a631-467ce19ce1ed",
      "metadata": {
        "id": "1c1f1700-a03d-43ae-a631-467ce19ce1ed",
        "outputId": "33810ea7-5956-417a-c7a5-fdfc119f8072"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 200/200 [03:08<00:00,  1.06it/s]\n",
            "100%|██████████| 200/200 [03:09<00:00,  1.06it/s]\n",
            "100%|██████████| 200/200 [03:09<00:00,  1.06it/s]\n",
            "100%|██████████| 200/200 [03:09<00:00,  1.06it/s]\n",
            "100%|██████████| 400/400 [06:18<00:00,  1.06it/s]\n",
            "100%|██████████| 400/400 [06:19<00:00,  1.05it/s]\n",
            "100%|██████████| 400/400 [06:19<00:00,  1.05it/s]\n",
            "100%|██████████| 400/400 [06:19<00:00,  1.06it/s]\n",
            "100%|██████████| 200/200 [03:09<00:00,  1.05it/s]\n",
            "100%|██████████| 200/200 [03:09<00:00,  1.05it/s]\n",
            "100%|██████████| 200/200 [03:09<00:00,  1.05it/s]\n",
            "100%|██████████| 200/200 [03:10<00:00,  1.05it/s]\n",
            " 13%|█▎        | 51/400 [00:51<05:30,  1.06it/s]"
          ]
        }
      ],
      "source": [
        "device = torch.device('cuda')\n",
        "\n",
        "exp_dir = \"../out\"\n",
        "G2 = models.get_model(\"stylegan2\", \"../pretrained/stylegan2/stylegan2-church-config-f.pkl\")\n",
        "stylegan2_sample_generator = StyleGAN2SampleGenerator(G=G2, device=device)\n",
        "\n",
        "deeplabv2_resnet101 = models.get_model(\"cocostuff_deeplab\",\n",
        "                                       \"../pretrained/cocostuff_deeplab/deeplabv2_resnet101_msc-cocostuff164k-100000.pth\")\n",
        "segmentation_model = StuffSegmentation(deeplabv2_resnet101=deeplabv2_resnet101, \n",
        "                                       config_path=\"../pretrained/cocostuff_deeplab/\", device=device)\n",
        "\n",
        "for latent_space in [\"Z\", \"W\", \"W+\"]:\n",
        "    for loss_function in [\"L2\"]:\n",
        "        for mask_aggregation in [\n",
        "            'average',\n",
        "            'union',\n",
        "            'intersection',\n",
        "        ]:\n",
        "\n",
        "            for num_latent_dirs in [1, 2]:\n",
        "                for part_name, sub_parts in zip(\n",
        "                        [\n",
        "                            \"church\",\n",
        "                            \"sky\", \"vegetation\", \"ground\"\n",
        "\n",
        "                        ],\n",
        "                        [\n",
        "                            [\"building-other\", \"house\"],\n",
        "                            [\"sky-other\", \"clouds\"],\n",
        "                            [\"tree\", \"grass\", \"bush\", \"plant-other\"],\n",
        "                            [\"dirt\", \"mud\", \"sand\", \"gravel\", \"ground-other\", \"road\", \"pavement\"],\n",
        "\n",
        "                        ]\n",
        "                ):\n",
        "                    lr = 0.001\n",
        "                    min_alpha_value = -1.0\n",
        "                    max_alpha_value = 1.0\n",
        "                    min_abs_alpha_value = 0.0\n",
        "                    gamma_correlation = 5.0\n",
        "                    onehot_temperature = 0.001\n",
        "                    batch_size = 4\n",
        "                    localization_layers = list(range(1, 14))\n",
        "                    localization_layer_weights = None\n",
        "                    log_dir = f'{exp_dir}/lelsd_stylegan2_lsun_church/{latent_space}_{loss_function}_{mask_aggregation}/{num_latent_dirs}D/deeplab/{part_name}'\n",
        "                    lelsd = LELSD(device=device,\n",
        "                                  localization_layers=localization_layers,\n",
        "                                  semantic_parts=sub_parts,\n",
        "                                  loss_function=loss_function,\n",
        "                                  localization_layer_weights=localization_layer_weights,\n",
        "                                  mode='foreground',\n",
        "                                  mask_aggregation=mask_aggregation,\n",
        "                                  n_layers=14,\n",
        "                                  latent_dim=512,\n",
        "                                  num_latent_dirs=num_latent_dirs,\n",
        "                                  learning_rate=lr,\n",
        "                                  batch_size=batch_size,\n",
        "                                  gamma_correlation=gamma_correlation,\n",
        "                                  unit_norm=False,\n",
        "                                  latent_space=latent_space,\n",
        "                                  onehot_temperature=onehot_temperature,\n",
        "                                  min_alpha_value=min_alpha_value,\n",
        "                                  max_alpha_value=max_alpha_value,\n",
        "                                  min_abs_alpha_value=min_abs_alpha_value,\n",
        "                                  log_dir=log_dir,\n",
        "                                  )\n",
        "\n",
        "                    lelsd.fit(stylegan2_sample_generator, segmentation_model, num_batches=200 * num_latent_dirs,\n",
        "                              num_lr_halvings=3,\n",
        "                              pgbar=True, summary=True)\n",
        "                    lelsd.save()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dc4514f1-a9e4-4db5-98f3-4646dfe823f2",
      "metadata": {
        "id": "dc4514f1-a9e4-4db5-98f3-4646dfe823f2"
      },
      "source": [
        "### StyleGAN2 LSUN Car"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7fb2be38-35ff-4f38-a7cf-97628c5fd937",
      "metadata": {
        "id": "7fb2be38-35ff-4f38-a7cf-97628c5fd937",
        "outputId": "835936fa-10bc-4db6-e183-b6a558198820"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 200/200 [03:29<00:00,  1.05s/it]\n",
            "100%|██████████| 200/200 [03:30<00:00,  1.05s/it]\n",
            "100%|██████████| 200/200 [03:30<00:00,  1.05s/it]\n",
            "100%|██████████| 200/200 [03:30<00:00,  1.05s/it]\n",
            "100%|██████████| 400/400 [07:01<00:00,  1.05s/it]\n",
            "100%|██████████| 400/400 [07:03<00:00,  1.06s/it]\n",
            "100%|██████████| 400/400 [07:01<00:00,  1.05s/it]\n",
            "100%|██████████| 400/400 [07:12<00:00,  1.08s/it]\n",
            "100%|██████████| 200/200 [03:33<00:00,  1.07s/it]\n",
            "100%|██████████| 200/200 [03:35<00:00,  1.08s/it]\n",
            "100%|██████████| 200/200 [03:33<00:00,  1.07s/it]\n",
            "100%|██████████| 200/200 [03:31<00:00,  1.06s/it]\n",
            "100%|██████████| 400/400 [07:02<00:00,  1.06s/it]\n",
            "100%|██████████| 400/400 [07:03<00:00,  1.06s/it]\n",
            "100%|██████████| 400/400 [07:08<00:00,  1.07s/it]\n",
            "100%|██████████| 400/400 [07:02<00:00,  1.06s/it]\n"
          ]
        }
      ],
      "source": [
        "device = torch.device('cuda')\n",
        "\n",
        "exp_dir = \"../out\"\n",
        "G2 = models.get_model(\"stylegan2\", \"../pretrained/stylegan2/stylegan2-car-config-f.pkl\")\n",
        "stylegan2_sample_generator = StyleGAN2SampleGenerator(G=G2, device=device)\n",
        "\n",
        "deeplabv2_resnet101 = models.get_model(\"cocostuff_deeplab\",\n",
        "                                       \"../pretrained/cocostuff_deeplab/deeplabv2_resnet101_msc-cocostuff164k-100000.pth\")\n",
        "segmentation_model = StuffSegmentation(deeplabv2_resnet101=deeplabv2_resnet101,\n",
        "                                       config_path=\"../pretrained/cocostuff_deeplab/\", device=device)\n",
        "\n",
        "for latent_space in [\"W\", \"W+\"]:\n",
        "    for loss_function in [\"L2\"]:\n",
        "        for mask_aggregation in [\n",
        "            'average',\n",
        "        ]:\n",
        "            for num_latent_dirs in [1, 2]:\n",
        "                for part_name, sub_parts in zip(\n",
        "                        [\n",
        "                            \"car\",\n",
        "                            \"road\", \"sky\", \"grass+tree\",\n",
        "\n",
        "                        ],\n",
        "                        [\n",
        "                            [\"car\", \"truck\", \"bus\", \"motorcycle\"],\n",
        "                            [\"road\", \"pavement\", \"dirt\"],\n",
        "                            [\"sky-other\", \"clouds\"],\n",
        "                            [\"tree\", \"grass\", \"bush\", \"plant-other\"],\n",
        "                        ]\n",
        "                ):\n",
        "                    lr = 0.001\n",
        "                    min_alpha_value = -1.0\n",
        "                    max_alpha_value = 1.0\n",
        "                    min_abs_alpha_value = 0.0\n",
        "                    gamma_correlation = 5.0\n",
        "                    onehot_temperature = 0.001\n",
        "                    batch_size = 4\n",
        "                    localization_layers = list(range(1, 16))\n",
        "                    localization_layer_weights = None\n",
        "                    log_dir = f'{exp_dir}/lelsd_stylegan2_lsun_car/{latent_space}_{loss_function}_{mask_aggregation}/{num_latent_dirs}D/deeplab/{part_name}'\n",
        "                    lelsd = LELSD(device=device,\n",
        "                                  localization_layers=localization_layers,\n",
        "                                  semantic_parts=sub_parts,\n",
        "                                  loss_function=loss_function,\n",
        "                                  localization_layer_weights=localization_layer_weights,\n",
        "                                  mode='foreground',\n",
        "                                  mask_aggregation=mask_aggregation,\n",
        "                                  n_layers=16,\n",
        "                                  latent_dim=512,\n",
        "                                  num_latent_dirs=num_latent_dirs,\n",
        "                                  learning_rate=lr,\n",
        "                                  batch_size=batch_size,\n",
        "                                  gamma_correlation=gamma_correlation,\n",
        "                                  unit_norm=False,\n",
        "                                  latent_space=latent_space,\n",
        "                                  onehot_temperature=onehot_temperature,\n",
        "                                  min_alpha_value=min_alpha_value,\n",
        "                                  max_alpha_value=max_alpha_value,\n",
        "                                  min_abs_alpha_value=min_abs_alpha_value,\n",
        "                                  log_dir=log_dir,\n",
        "                                  )\n",
        "\n",
        "                    lelsd.fit(stylegan2_sample_generator, segmentation_model, num_batches=200 * num_latent_dirs,\n",
        "                              num_lr_halvings=3,\n",
        "                              pgbar=True, summary=True)\n",
        "                    lelsd.save()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9f89ace7-be9b-4c34-890f-1d07f829c136",
      "metadata": {
        "id": "9f89ace7-be9b-4c34-890f-1d07f829c136"
      },
      "source": [
        "### StyleGAN2 LSUN Horse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1a2d5101-9f30-4b9a-b5da-83a329eab036",
      "metadata": {
        "id": "1a2d5101-9f30-4b9a-b5da-83a329eab036",
        "outputId": "4393aa5f-0e3c-49d4-b7c5-be7b50a8aeb5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 200/200 [03:08<00:00,  1.06it/s]\n",
            "100%|██████████| 200/200 [03:08<00:00,  1.06it/s]\n",
            "100%|██████████| 200/200 [03:08<00:00,  1.06it/s]\n",
            "100%|██████████| 200/200 [03:09<00:00,  1.06it/s]\n",
            "100%|██████████| 200/200 [03:09<00:00,  1.06it/s]\n",
            "100%|██████████| 400/400 [06:18<00:00,  1.06it/s]\n",
            "100%|██████████| 400/400 [06:18<00:00,  1.06it/s]\n",
            "100%|██████████| 400/400 [06:17<00:00,  1.06it/s]\n",
            "100%|██████████| 400/400 [06:18<00:00,  1.06it/s]\n",
            "100%|██████████| 400/400 [06:17<00:00,  1.06it/s]\n",
            " 40%|████      | 80/200 [01:15<01:53,  1.06it/s]"
          ]
        }
      ],
      "source": [
        "device = torch.device('cuda')\n",
        "\n",
        "exp_dir = \"../out\"\n",
        "G2 = models.get_model(\"stylegan2\", \"../pretrained/stylegan2/stylegan2-horse-config-f.pkl\")\n",
        "stylegan2_sample_generator = StyleGAN2SampleGenerator(G=G2, device=device)\n",
        "\n",
        "deeplabv2_resnet101 = models.get_model(\"cocostuff_deeplab\",\n",
        "                                       \"../pretrained/cocostuff_deeplab/deeplabv2_resnet101_msc-cocostuff164k-100000.pth\")\n",
        "segmentation_model = StuffSegmentation(deeplabv2_resnet101=deeplabv2_resnet101,\n",
        "                                       config_path=\"../pretrained/cocostuff_deeplab/\", device=device)\n",
        "\n",
        "for latent_space in [\"W\", \"W+\"]:\n",
        "    for loss_function in [\"L2\"]:\n",
        "        for mask_aggregation in [\n",
        "            'average',\n",
        "        ]:\n",
        "            for num_latent_dirs in [1, 2]:\n",
        "                for part_name, sub_parts in zip(\n",
        "                        [\n",
        "                            \"horse\",\n",
        "                            \"person\", \"sky\", \"grass+tree\", \"ground\"\n",
        "\n",
        "                        ],\n",
        "                        [\n",
        "                            [\"horse\"],\n",
        "                            [\"person\"],\n",
        "                            [\"sky-other\", \"clouds\"],\n",
        "                            [\"tree\", \"grass\", \"bush\", \"plant-other\"],\n",
        "                            [\"dirt\", \"mud\", \"sand\", \"gravel\", \"ground-other\", \"road\", \"pavement\"],\n",
        "\n",
        "                        ]\n",
        "                ):\n",
        "                    lr = 0.001\n",
        "                    min_alpha_value = -1.0\n",
        "                    max_alpha_value = 1.0\n",
        "                    min_abs_alpha_value = 0.0\n",
        "                    gamma_correlation = 5.0\n",
        "                    onehot_temperature = 0.001\n",
        "                    batch_size = 4\n",
        "                    localization_layers = list(range(1, 14))\n",
        "                    localization_layer_weights = None\n",
        "                    log_dir = f'{exp_dir}/lelsd_stylegan2_lsun_horse/{latent_space}_{loss_function}_{mask_aggregation}/{num_latent_dirs}D/deeplab/{part_name}'\n",
        "                    lelsd = LELSD(device=device,\n",
        "                                  localization_layers=localization_layers,\n",
        "                                  semantic_parts=sub_parts,\n",
        "                                  loss_function=loss_function,\n",
        "                                  localization_layer_weights=localization_layer_weights,\n",
        "                                  mode='foreground',\n",
        "                                  mask_aggregation=mask_aggregation,\n",
        "                                  n_layers=14,\n",
        "                                  latent_dim=512,\n",
        "                                  num_latent_dirs=num_latent_dirs,\n",
        "                                  learning_rate=lr,\n",
        "                                  batch_size=batch_size,\n",
        "                                  gamma_correlation=gamma_correlation,\n",
        "                                  unit_norm=False,\n",
        "                                  latent_space=latent_space,\n",
        "                                  onehot_temperature=onehot_temperature,\n",
        "                                  min_alpha_value=min_alpha_value,\n",
        "                                  max_alpha_value=max_alpha_value,\n",
        "                                  min_abs_alpha_value=min_abs_alpha_value,\n",
        "                                  log_dir=log_dir,\n",
        "                                  )\n",
        "\n",
        "                    lelsd.fit(stylegan2_sample_generator, segmentation_model, num_batches=200 * num_latent_dirs,\n",
        "                              num_lr_halvings=3,\n",
        "                              pgbar=True, summary=True)\n",
        "                    lelsd.save()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c161aa35-adff-41ce-8855-2c76a212b5c9",
      "metadata": {
        "id": "c161aa35-adff-41ce-8855-2c76a212b5c9"
      },
      "source": [
        "### StyleGAN2 MetFaces"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c7d4206-cb07-483e-9b0d-80d0bdd6a93a",
      "metadata": {
        "id": "3c7d4206-cb07-483e-9b0d-80d0bdd6a93a"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda')\n",
        "\n",
        "exp_dir = \"../out\"\n",
        "G2 = models.get_model(\"stylegan2\", \"../pretrained/stylegan2/metfaces.pkl\")\n",
        "stylegan2_sample_generator = StyleGAN2SampleGenerator(G=G2, device=device)\n",
        "\n",
        "face_bisenet = models.get_model(\"face_bisenet\", \"../pretrained/face_bisenet/model.pth\")\n",
        "face_segmentation = FaceSegmentation(face_bisenet=face_bisenet, device=device)\n",
        "\n",
        "for latent_space in [\"W\", \"W+\"]:\n",
        "    for loss_function in [\"L2\"]:\n",
        "        for mask_aggregation in [\n",
        "            'average',\n",
        "        ]:\n",
        "\n",
        "            for num_latent_dirs in [1, 2]:\n",
        "                for part_name, face_parts in zip(\n",
        "                        [\n",
        "                            \"mouth\",\n",
        "                            \"skin\",\n",
        "                            \"eyes\",\n",
        "                            \"nose\",\n",
        "                            \"ears\",\n",
        "                            \"background\",\n",
        "                            \"eyebrows\",\n",
        "                            \"hair\",\n",
        "                            \"cloth\",\n",
        "                        ],\n",
        "                        [\n",
        "                            [\"mouth\", \"u_lip\", \"l_lip\"],\n",
        "                            [\"skin\"],\n",
        "                            [\"l_eye\", \"r_eye\"],\n",
        "                            [\"nose\"],\n",
        "                            [\"l_ear\", \"r_ear\", \"earrings\"],\n",
        "                            [\"background\"],\n",
        "                            [\"l_brow\", \"r_brow\"],\n",
        "                            [\"hair\", \"hat\"],\n",
        "                            [\"hair\"],\n",
        "                            [\"cloth\", \"neck\", \"necklace\"],\n",
        "\n",
        "                        ]\n",
        "                ):\n",
        "                    lr = 0.001\n",
        "                    min_alpha_value = -1.0\n",
        "                    max_alpha_value = 1.0\n",
        "                    min_abs_alpha_value = 0.0\n",
        "                    gamma_correlation = 5.0\n",
        "                    onehot_temperature = 0.001\n",
        "                    batch_size = 4\n",
        "                    localization_layers = list(range(1, 18))\n",
        "                    localization_layer_weights = None\n",
        "                    log_dir = f'{exp_dir}/lelsd_stylegan2_metfaces/{latent_space}_{loss_function}_{mask_aggregation}/{num_latent_dirs}D/face_bisenet/{part_name}'\n",
        "                    lelsd = LELSD(device=device,\n",
        "                                  localization_layers=localization_layers,\n",
        "                                  semantic_parts=face_parts,\n",
        "                                  loss_function=loss_function,\n",
        "                                  localization_layer_weights=localization_layer_weights,\n",
        "                                  mode='foreground',\n",
        "                                  mask_aggregation=mask_aggregation,\n",
        "                                  n_layers=18,\n",
        "                                  latent_dim=512,\n",
        "                                  num_latent_dirs=num_latent_dirs,\n",
        "                                  learning_rate=lr,\n",
        "                                  batch_size=batch_size,\n",
        "                                  gamma_correlation=gamma_correlation,\n",
        "                                  unit_norm=False,\n",
        "                                  latent_space=latent_space,\n",
        "                                  onehot_temperature=onehot_temperature,\n",
        "                                  min_alpha_value=min_alpha_value,\n",
        "                                  max_alpha_value=max_alpha_value,\n",
        "                                  min_abs_alpha_value=min_abs_alpha_value,\n",
        "                                  log_dir=log_dir,\n",
        "                                  )\n",
        "\n",
        "                    lelsd.fit(stylegan2_sample_generator, face_segmentation, num_batches=200 * num_latent_dirs,\n",
        "                              num_lr_halvings=3,\n",
        "                              pgbar=True, summary=True)\n",
        "                    lelsd.save()\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    },
    "colab": {
      "name": "train_lelsd_stylegan2.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}